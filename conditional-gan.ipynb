{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchsummary import summary\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ConditionalGenerator, Classificator\n",
    "from utils import noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the runs folder\n",
    "if os.path.exists(\"runs\"):\n",
    "    os.system(\"rm -r runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fashion mnist dataset\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainset = datasets.FashionMNIST(\n",
    "    \"~/.pytorch/F_MNIST_data/\", download=True, train=True, transform=transform\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = datasets.FashionMNIST(\n",
    "    \"~/.pytorch/F_MNIST_data/\", download=True, train=False, transform=transform\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 70\n",
    "n_classes = len(trainset.classes)\n",
    "latent_dim = 100\n",
    "embedding_dim = 100\n",
    "lr = 0.00001\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss_D = nn.BCELoss()\n",
    "\n",
    "G = ConditionalGenerator(\n",
    "    n_classes=n_classes, embedding_dim=embedding_dim, latent_dim=latent_dim\n",
    ").to(device)\n",
    "D = Classificator(1, embedding_dim=embedding_dim, n_classes=n_classes).to(device)\n",
    "G_optim = optim.Adam(G.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "D_optim = optim.Adam(D.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "\n",
    "G_scheduler = lr_scheduler.StepLR(G_optim, step_size=30, gamma=0.1)\n",
    "D_scheduler = lr_scheduler.StepLR(D_optim, step_size=30, gamma=0.1)\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0112c14bd78e44f0bc55934a10d00429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65660 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fixed_noise = noise(50, latent_dim).to(device)\n",
    "fixed_labels = torch.tensor([i for i in range(10) for _ in range(5)]).long().to(device)\n",
    "fixed_outputs = []\n",
    "all_labels = torch.tensor([i for i in range(10)]).long().to(device)\n",
    "\n",
    "pbar = tqdm(total=epochs * len(trainloader))\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "\n",
    "        batch_size = images.size(0)\n",
    "        images = images.to(device)\n",
    "        labels = labels.long().to(device)\n",
    "\n",
    "        # Train Discriminator\n",
    "        D_optim.zero_grad()\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        real_output = D(images, labels)\n",
    "        real_loss = Loss_D(real_output, real_labels)\n",
    "\n",
    "        z = noise(batch_size, latent_dim).to(device)\n",
    "        fake_images = G(z, labels)\n",
    "        fake_output = D(fake_images.detach(), labels)\n",
    "        fake_loss = Loss_D(fake_output, fake_labels)\n",
    "\n",
    "        D_loss = real_loss + fake_loss\n",
    "        D_loss.backward()\n",
    "        D_optim.step()\n",
    "\n",
    "        # Train Generator\n",
    "        G_optim.zero_grad()\n",
    "        z = noise(batch_size, latent_dim).to(device)\n",
    "        fake_images = G(z, labels)\n",
    "        fake_output = D(fake_images, labels)\n",
    "\n",
    "        G_loss = Loss_D(fake_output, real_labels)\n",
    "        G_loss.backward()\n",
    "        G_optim.step()\n",
    "\n",
    "        pbar.update()\n",
    "        if i % 50 == 0:\n",
    "            pbar.set_description(\n",
    "                f\"Epoch: {epoch}, Iteration: {i}, D_loss: {D_loss.item():.3f}, G_loss: {G_loss.item():.3f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                G.eval()\n",
    "                fixed_output = ((G(fixed_noise, fixed_labels) + 1) / 2).clamp(0, 1)\n",
    "                fixed_outputs.append(fixed_output.detach().cpu())\n",
    "                writer.add_images(\n",
    "                    \"generated\",\n",
    "                    make_grid(fixed_output, nrow=5).unsqueeze(0),\n",
    "                    epoch * len(trainloader) + i,\n",
    "                )\n",
    "                G.train()\n",
    "\n",
    "        writer.add_scalar(\"D_loss\", D_loss.item(), epoch * len(trainloader) + i)\n",
    "        writer.add_scalar(\"G_loss\", G_loss.item(), epoch * len(trainloader) + i)\n",
    "\n",
    "    G_scheduler.step()\n",
    "    D_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer.close()\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "images = [\n",
    "    [\n",
    "        plt.imshow(\n",
    "            make_grid(fixed_output, nrow=5).permute(1, 2, 0).numpy(),\n",
    "            cmap=\"gray\",\n",
    "            animated=True,\n",
    "        )\n",
    "    ]\n",
    "    for fixed_output in fixed_outputs\n",
    "]\n",
    "\n",
    "ani = animation.ArtistAnimation(fig, images, interval=200, repeat_delay=10000)\n",
    "ani.save(\"fashion_mnist.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the discriminator\n",
    "\n",
    "confusion_matrices = np.zeros((n_classes, 2, 2))\n",
    "\n",
    "D.eval()\n",
    "G.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = D(images, labels)\n",
    "\n",
    "        predicted = outputs > 0.5\n",
    "\n",
    "        for label, pred in zip(labels, predicted):\n",
    "            confusion_matrices[label][pred][1] += 1\n",
    "\n",
    "        z = noise(batch_size, latent_dim).to(device)\n",
    "        fake_images = G(z, labels)\n",
    "        outputs = D(fake_images, labels)\n",
    "\n",
    "        predicted = outputs > 0.5\n",
    "\n",
    "        for label, pred in zip(labels, predicted):\n",
    "            confusion_matrices[label][pred][0] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for class 0: \n",
      "[[1000.  231.]\n",
      " [   0.  769.]]\n",
      "Confusion matrix for class 1: \n",
      "[[1000.  396.]\n",
      " [   0.  604.]]\n",
      "Confusion matrix for class 2: \n",
      "[[1000.  381.]\n",
      " [   0.  619.]]\n",
      "Confusion matrix for class 3: \n",
      "[[1000.  445.]\n",
      " [   0.  555.]]\n",
      "Confusion matrix for class 4: \n",
      "[[1000.  320.]\n",
      " [   0.  680.]]\n",
      "Confusion matrix for class 5: \n",
      "[[1000.  347.]\n",
      " [   0.  653.]]\n",
      "Confusion matrix for class 6: \n",
      "[[1000.  353.]\n",
      " [   0.  647.]]\n",
      "Confusion matrix for class 7: \n",
      "[[1000.  566.]\n",
      " [   0.  434.]]\n",
      "Confusion matrix for class 8: \n",
      "[[1000.  527.]\n",
      " [   0.  473.]]\n",
      "Confusion matrix for class 9: \n",
      "[[1000.  400.]\n",
      " [   0.  600.]]\n",
      "Overall confusion matrix :  \n",
      "[[10000.  3966.]\n",
      " [    0.  6034.]]\n",
      "Accuracy: 0.8017\n",
      "Precision: 1.0\n",
      "Recall: 0.6034\n",
      "False positive rate: 0.0\n"
     ]
    }
   ],
   "source": [
    "for i, confusion_matrix in enumerate(confusion_matrices):\n",
    "    print(f\"Confusion matrix for class {i}: \\n{confusion_matrix}\")\n",
    "\n",
    "print(f\"Overall confusion matrix :  \\n{confusion_matrices.sum(axis=0)}\")\n",
    "\n",
    "print(f\"Accuracy: {confusion_matrices.sum(axis=0).trace() / confusion_matrices.sum()}\")\n",
    "print(f\"Precision: {confusion_matrices[:, 1, 1].sum() / confusion_matrices[:, 1].sum()}\")\n",
    "print(f\"Recall: {confusion_matrices[:, 1, 1].sum() / confusion_matrices[:, :, 1].sum()}\")\n",
    "print(\n",
    "    f\"False positive rate: {confusion_matrices[:, 1, 0].sum() / confusion_matrices[:, :, 0].sum()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the Discriminator has the edge on the Generator, making near perfect classification of generated samples (only misclassifying them 0.1% of the time), at the cost of quite a few misclassifications on the original dataset, maintaining however a 81% recall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
